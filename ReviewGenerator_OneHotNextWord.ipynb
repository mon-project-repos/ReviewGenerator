{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReviewGenerator_OneHotNextWord.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mon-project-repos/ReviewGenerator/blob/master/ReviewGenerator_OneHotNextWord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGbmN2EftUsS",
        "colab_type": "text"
      },
      "source": [
        "# 0. Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxZvA4s4xLL",
        "colab_type": "text"
      },
      "source": [
        "## GPU Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkBZ7p5NtOWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up session \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJUYaouI4rm3",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4552K9UXtcXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "# nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US5tgJL94vIj",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6aJcFu44KAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dta = pickle.load(open(\"gdrive/My Drive/dta_review.pkl\",'rb'))\n",
        "\n",
        "dta = dta.loc[dta['prod_total']>100]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('Total',dta.shape)\n",
        "\n",
        "\n",
        "\n",
        "corpus = dta['review_data']\n",
        "dta = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J8QN-sq6EdW",
        "colab_type": "text"
      },
      "source": [
        "# NLP preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qaz4-rAy6Zwq",
        "colab_type": "text"
      },
      "source": [
        "## User and Product Documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQO8pFZ-_7jL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(corpus)\n",
        "percent_validation = .2\n",
        "last_train = int(len(corpus)*(1-percent_validation))\n",
        "print(corpus[last_train-1])\n",
        "corpus_train, corpus_validation = corpus[:last_train], corpus[last_train:]\n",
        "corpus = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBhnTlnT6_WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_train = (\" end-of_review  \").join(corpus_train)\n",
        "sents_train = nltk.sent_tokenize(corpus_train)\n",
        "len(sents_train) \n",
        "#remove_filters='\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n' # don't remove anything as they may be emojis\n",
        "max_vocab_words = 500\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = max_vocab_words+1,\n",
        "                                                  lower=True, \n",
        "                                                  filters=\"\",\n",
        "                                                 oov_token=\"<OOV>\",char_level=False)\n",
        "\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(sents_train)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "\n",
        "print(len(tokenizer.word_index))\n",
        "print(len(tokenizer.word_counts))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhBLAcVK3pcI",
        "colab_type": "text"
      },
      "source": [
        "## Create input sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tesuUl8FP26I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen_ngram = 30\n",
        "review_sequences = []\n",
        "for review in sents_train:\n",
        "    tokenized_review = tokenizer.texts_to_sequences([review])[0] #map each word to word_index \n",
        "    #print(len(tokenized_review))\n",
        "    for i in range(1, min( [maxlen_ngram,len(tokenized_review)])): # make ngrams\n",
        "        review_sequences.append( tokenized_review[:i+1] )\n",
        "        \n",
        "# get max length \n",
        "max_review_len = max([len(x) for x in review_sequences])\n",
        "print(max_review_len)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLUD_WT_4tFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "review_sequences = np.array(pad_sequences(review_sequences,\n",
        "                                         maxlen=maxlen_ngram,\n",
        "                                         padding='pre'))    \n",
        "    \n",
        "# generate set of last words in sequence\n",
        "predictors, last_word = review_sequences[:,:-1] , review_sequences[:,-1]\n",
        "last_word = tf.keras.utils.to_categorical(last_word, num_classes=max_vocab_words+1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us9WVABDs4C0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "175280bd-6d02-4aee-9ea6-97691bd7f1f0"
      },
      "source": [
        "corpus_validation = (\" end-of-review  \").join(corpus_validation)\n",
        "sents_validation = nltk.sent_tokenize(corpus_validation)\n",
        "review_sequences_validation = []\n",
        "\n",
        "for review in sents_validation:\n",
        "    \n",
        "    tokenized_review = tokenizer.texts_to_sequences([review])[0]\n",
        "    for i in  range(1, min([maxlen_ngram, len(tokenized_review)])): # make ngrams\n",
        "        review_sequences_validation.append( tokenized_review[:i+1] )\n",
        "        \n",
        "# get max length \n",
        "max_review_len_validation = max([len(x) for x in review_sequences_validation])\n",
        "print(max_review_len_validation)\n",
        "        \n",
        "    \n",
        "review_sequences_validation = np.array(pad_sequences(review_sequences_validation,\n",
        "                                         maxlen=maxlen_ngram,\n",
        "                                         padding='pre', truncating='post'))    \n",
        "    \n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD_a9F7GAxiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate set of last words in sequence\n",
        "predictors_validation, last_word_validation = review_sequences_validation[:,:-1] , review_sequences_validation[:,-1]\n",
        "last_word_validation = tf.keras.utils.to_categorical(last_word_validation, num_classes=max_vocab_words+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t65YGzsFBzzz",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNAi-z8I7uYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(max_vocab_words +1 , maxlen_ngram, input_length=max_review_len-1))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences = True)))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(40))\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(tf.keras.layers.Dense(max_vocab_words +1, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrJmz8ouT8Dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class earlyStopCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('acc')> 0.7):\n",
        "            print(\"\\n Training Accuracy is 0.9.  Stopping here\")\n",
        "            self.model.stop_training = True\n",
        "         \n",
        "callbacks = earlyStopCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBGv3ocHOmTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(predictors, last_word, \n",
        "                    epochs=20, \n",
        "                    verbose = 2, \n",
        "                    validation_data = (predictors_validation,last_word_validation),\n",
        "#                    validation_split=0.2, \n",
        "                    batch_size = 512, \n",
        "                    callbacks = [callbacks])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCTIyvxlTnWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r')\n",
        "plt.plot(epochs, val_loss, 'b')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Loss\", \"Validation Loss\"])\n",
        "\n",
        "plt.figure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wsGdpVSPRsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = \"OMG!  \"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=maxlen_ngram-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuh0-gCMR4fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}