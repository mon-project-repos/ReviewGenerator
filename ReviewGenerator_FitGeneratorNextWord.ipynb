{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReviewGenerator_FitGeneratorNextWord.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mon-project-repos/ReviewGenerator/blob/master/ReviewGenerator_FitGeneratorNextWord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGbmN2EftUsS",
        "colab_type": "text"
      },
      "source": [
        "# 0. Preliminaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxZvA4s4xLL",
        "colab_type": "text"
      },
      "source": [
        "## GPU Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkBZ7p5NtOWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up session \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJUYaouI4rm3",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4552K9UXtcXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "#import matplotlib.pyplot as plt\n",
        "#%matplotlib ipympl\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(['dark_background'])\n",
        "\n",
        "import nltk\n",
        "# nltk.download('stopwords')\n",
        "#nltk.download('punkt')\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US5tgJL94vIj",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oGwgnQv41-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "percent_validation = 0.2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6aJcFu44KAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dta = pickle.load(open(\"gdrive/My Drive/dta_review.pkl\",'rb'))\n",
        "dta = dta.loc[dta['prod_total']>100]\n",
        "first_validate = int(len(dta)*(1-percent_validation))\n",
        "print('Total',dta.shape, 'first validate:' ,first_validate)\n",
        "\n",
        "review_train = dta['review_data'].iloc[:first_validate]\n",
        "review_validate = dta['review_data'].iloc[first_validate: ]\n",
        "#corpus_train = (\" end-of-review \").join( )\n",
        "#corpus_validation = (\" end-of-review \").join( dta['review_data'].iloc[first_validate:])\n",
        "dta = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J8QN-sq6EdW",
        "colab_type": "text"
      },
      "source": [
        "# NLP preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qaz4-rAy6Zwq",
        "colab_type": "text"
      },
      "source": [
        "## User and Product Documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBhnTlnT6_WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#remove_filters='\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n' # don't remove anything as they may be emojis\n",
        "max_vocab_words = 10000\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = max_vocab_words+1,\n",
        "                                                  lower=True, \n",
        "                                                  filters=\"\",\n",
        "                                                 oov_token=\"<OOV>\",\n",
        "                                                  char_level=False)\n",
        "\n",
        "\n",
        "corpus_train = (\" endOfReview/n\").join(review_train)\n",
        "tokenizer.fit_on_texts(tf.keras.preprocessing.text.text_to_word_sequence(corpus_train))\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "word_freq = tokenizer.word_counts\n",
        "word_idx = tokenizer.word_index\n",
        "print(word_idx)\n",
        "print(word_freq)\n",
        "\n",
        "#print(len(tokenizer.word_index))\n",
        "print(len(word_freq))\n",
        "\n",
        "idx_word = {v:k for k,v in word_idx.items()}\n",
        "print(idx_word)\n",
        "print(len(idx_word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHQ7R0aXqKZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e20a0d06-b7f6-47c0-8b3f-ab4ee49467c6"
      },
      "source": [
        "print(review_train[0])\n",
        "print( tokenizer.texts_to_sequences([review_train[0]])[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I have tried all different styles of Asics for running shoes, Contend, Cumulus, Nimbus, Scram,  GT-1000, and GT-2000. All have been great shoes with the exception of the Scram which are technically trail runners but they were just to narrow in the toe box. These are a bit stiffer than other Asics but I hope that means they will hold up. They don't have as much cushion as the Cumulus or Nimbus and I will be going back to one of those for running. These are still good shoes, I just prefer the others.Edit:  These were bothering my feet while running. I bought gel inserts and they are so much better! The original inserts have no cushioning at all. \n",
            "[3, 19, 224, 43, 182, 762, 17, 99, 11, 69, 1, 1, 1, 1, 1, 1, 5, 1, 43, 19, 104, 32, 8, 28, 4, 1649, 17, 4, 5926, 139, 13, 4899, 689, 1048, 18, 9, 45, 49, 7, 133, 15, 4, 122, 1, 14, 13, 6, 130, 1650, 66, 96, 99, 18, 3, 480, 33, 1305, 9, 53, 446, 1, 9, 128, 19, 34, 108, 269, 34, 4, 1846, 73, 648, 5, 3, 53, 44, 222, 110, 7, 112, 17, 425, 11, 1, 14, 13, 136, 41, 1, 3, 49, 821, 4, 1, 14, 45, 3253, 10, 37, 259, 1, 3, 64, 317, 411, 5, 9, 13, 24, 108, 1, 4, 714, 411, 19, 82, 410, 52, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhBLAcVK3pcI",
        "colab_type": "text"
      },
      "source": [
        "## Create input sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tesuUl8FP26I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len_ngram = 20\n",
        "\n",
        "def get_sequences(reviews,  len_ngram=20):\n",
        "    sequences = []\n",
        "    review_sentences = \" endOfReview/n\".join(reviews)\n",
        "    review_tokens = tokenizer.texts_to_sequences([review_sentences])[0] #map each word to word_index \n",
        "    #for review in review_sentences:\n",
        "        #review_words = review + \" endOfReview/n\"\n",
        "        #tokenized_review = tokenizer.texts_to_sequences([review_words])[0] #map each word to word_index \n",
        "        #print(len(tokenized_review))\n",
        "    #for i in range(1, min( [maxlen_ngram,len(review_words)])): # make ngrams\n",
        "    for i in range(len_ngram, len(review_tokens)):\n",
        "        sequences.append( review_tokens[i-len_ngram:i] )\n",
        "    #if max_review_len is None:\n",
        "    #    max_review_len = max([len(x) for x in sequences])\n",
        "    #print(max_review_len)\n",
        "    #sequences = np.array(pad_sequences(sequences,\n",
        "    #                                     maxlen=maxlen_ngram,\n",
        "    #                                     padding='pre')) \n",
        "    return np.array(sequences) #, max_review_len\n",
        "        \n",
        "def get_pred_lastword(sequences):\n",
        "    predictors, last_word = sequences[:,:-1] , sequences[:,-1]\n",
        "    #last_word = tf.keras.utils.to_categorical(last_word, num_classes=max_vocab_words+1)\n",
        "    return (predictors, last_word )\n",
        "\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZNV14gWCG6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get max length \n",
        "len_ngram = 20\n",
        "train_sequences = get_sequences(review_train,len_ngram=len_ngram)\n",
        "pred_train, lastword_train = get_pred_lastword(train_sequences)\n",
        "\n",
        "validate_sequences = get_sequences(review_validate, len_ngram=len_ngram)\n",
        "pred_validate, lastword_validate = get_pred_lastword(validate_sequences)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w5QDbxyh80C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "1d641c37-17b0-42cd-ccf5-33e80ad91b7c"
      },
      "source": [
        "print('x=', pred_train.shape, 'y=', lastword_train.shape)\n",
        "print(pred_train[:3])\n",
        "print(lastword_train[:3])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x= (1667162, 19) y= (1667162,)\n",
            "[[  3  19 224  43 182 762  17  99  11  69   1   1   1   1   1   1   5   1\n",
            "   43]\n",
            " [ 19 224  43 182 762  17  99  11  69   1   1   1   1   1   1   5   1  43\n",
            "   19]\n",
            " [224  43 182 762  17  99  11  69   1   1   1   1   1   1   5   1  43  19\n",
            "  104]]\n",
            "[ 19 104  32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t65YGzsFBzzz",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxt3ZicDGZJ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "c650b1bd-d07e-4c96-ae11-517f33097405"
      },
      "source": [
        "# model = tf.keras.models.Sequential()\n",
        "# model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128), \n",
        "#                                         input_shape=(maxlen_ngram, max_vocab_words)))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.Dense(max_vocab_words))\n",
        "# model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "\n",
        "print(pred_train.shape)\n",
        "print(lastword_train.shape)\n",
        "for m in range(24):\n",
        "    print((\" \").join([idx_word[i] if i>0 else \"\" for i in train_sequences[m]]))\n",
        "\n",
        "print(review_train[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1667162, 19)\n",
            "(1667162,)\n",
            "i have tried all different styles of asics for running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have\n",
            "have tried all different styles of asics for running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been\n",
            "tried all different styles of asics for running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great\n",
            "all different styles of asics for running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes\n",
            "different styles of asics for running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes with\n",
            "styles of asics for running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes with the\n",
            "of asics for running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes with the exception\n",
            "asics for running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes with the exception of\n",
            "for running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes with the exception of the\n",
            "running <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes with the exception of the scram\n",
            "<OOV> <OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes with the exception of the scram which\n",
            "<OOV> <OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes with the exception of the scram which are\n",
            "<OOV> <OOV> <OOV> <OOV> and <OOV> all have been great shoes with the exception of the scram which are technically\n",
            "<OOV> <OOV> <OOV> and <OOV> all have been great shoes with the exception of the scram which are technically trail\n",
            "<OOV> <OOV> and <OOV> all have been great shoes with the exception of the scram which are technically trail runners\n",
            "<OOV> and <OOV> all have been great shoes with the exception of the scram which are technically trail runners but\n",
            "and <OOV> all have been great shoes with the exception of the scram which are technically trail runners but they\n",
            "<OOV> all have been great shoes with the exception of the scram which are technically trail runners but they were\n",
            "all have been great shoes with the exception of the scram which are technically trail runners but they were just\n",
            "have been great shoes with the exception of the scram which are technically trail runners but they were just to\n",
            "been great shoes with the exception of the scram which are technically trail runners but they were just to narrow\n",
            "great shoes with the exception of the scram which are technically trail runners but they were just to narrow in\n",
            "shoes with the exception of the scram which are technically trail runners but they were just to narrow in the\n",
            "with the exception of the scram which are technically trail runners but they were just to narrow in the toe\n",
            "I have tried all different styles of Asics for running shoes, Contend, Cumulus, Nimbus, Scram,  GT-1000, and GT-2000. All have been great shoes with the exception of the Scram which are technically trail runners but they were just to narrow in the toe box. These are a bit stiffer than other Asics but I hope that means they will hold up. They don't have as much cushion as the Cumulus or Nimbus and I will be going back to one of those for running. These are still good shoes, I just prefer the others.Edit:  These were bothering my feet while running. I bought gel inserts and they are so much better! The original inserts have no cushioning at all. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSQKfFLBHZYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(pred_list, next_word_list, batch_size):\n",
        "    index = 0\n",
        "    while True:\n",
        "        last_idx = min([ index+batch_size, len(pred_list)])\n",
        "        x = pred_list[index:last_idx,:]\n",
        "        y = tf.keras.utils.to_categorical(next_word_list[index:last_idx], num_classes = max_vocab_words+1)\n",
        "        index = index+batch_size if index+batch_size<len(pred_list) else 0\n",
        "        yield x, y\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDqi_rNLHYVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNAi-z8I7uYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(max_vocab_words +1 , len_ngram, input_length=len_ngram-1))\n",
        "#model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True)))\n",
        "model.add(tf.keras.layers.LSTM(32, return_sequences=True))\n",
        "#model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(16))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "#model.add(tf.keras.layers.Dense(10, activation='relu'))#, kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(tf.keras.layers.Dense(max_vocab_words +1, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrJmz8ouT8Dr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class earlyStopCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('acc')> 0.9):\n",
        "            print(\"\\n Training Accuracy is 0.9.  Stopping here\")\n",
        "            self.model.stop_training = True\n",
        "         \n",
        "callbacks = earlyStopCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBTLVfgaxDuF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "97a5a071-c1c5-4f41-8b0c-7cc7e5f6e32d"
      },
      "source": [
        "batch_size = 2048\n",
        "history = model.fit_generator(generator(pred_train, lastword_train, batch_size),\n",
        "                   steps_per_epoch = int(len(pred_train)/batch_size)+1,\n",
        "                   epochs=3,\n",
        "                   callbacks=[callbacks],\n",
        "                   validation_data=generator(pred_validate, lastword_validate, batch_size),\n",
        "                   validation_steps = int(len(pred_validate)/batch_size)+1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "815/815 [==============================] - 748s 918ms/step - loss: 5.7762 - acc: 0.1686 - val_loss: 5.3880 - val_acc: 0.1618\n",
            "Epoch 2/3\n",
            "815/815 [==============================] - 741s 910ms/step - loss: 5.3180 - acc: 0.1718 - val_loss: 5.3852 - val_acc: 0.1618\n",
            "Epoch 3/3\n",
            "815/815 [==============================] - 741s 909ms/step - loss: 5.3145 - acc: 0.1718 - val_loss: 5.3846 - val_acc: 0.1618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCTIyvxlTnWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r-.')\n",
        "plt.plot(epochs, val_acc, 'b')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r-.')\n",
        "plt.plot(epochs, val_loss, 'b')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Loss\", \"Validation Loss\"])\n",
        "\n",
        "plt.figure()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuh0-gCMR4fe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "6eda6434-5b1a-46d2-f058-3e7b282c84e0"
      },
      "source": [
        "seed_text = \"These shoes\"\n",
        "next_words = 10\n",
        "\n",
        "for m in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=len_ngram-1, padding='pre')\n",
        "    predicted = model.predict_classes(token_list, verbose=0)\n",
        "    output_word = \"\"\n",
        "    if predicted[0] in idx_word:\n",
        "        output_word = idx_word[predicted[0]]\n",
        "    seed_text += output_word\n",
        "    \n",
        "print(seed_text)\n",
        "\n",
        "        "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These shoes<OOV><OOV><OOV><OOV><OOV><OOV><OOV><OOV><OOV><OOV>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}